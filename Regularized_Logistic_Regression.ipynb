{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4sH8y0rPGo8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/sample_data/catsvsdogs_features_SqueezeNet_1.csv')\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "aEIpI9WoGUc6",
        "outputId": "4e3f679a-2d52-4759-f18d-dc682f4d950c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        0\n",
              "0.364    0\n",
              "2.496    0\n",
              "0.269    0\n",
              "0.0      0\n",
              "        ..\n",
              "2.277    0\n",
              "4.903    0\n",
              "0.381    0\n",
              "7.209    0\n",
              "1.0      0\n",
              "Length: 514, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.364</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.496</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.269</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.277</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4.903</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.381</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7.209</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>514 rows Ã— 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    \"\"\"Sigmoid activation function.\"\"\"\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "\n",
        "def compute_cost(X, y, theta, lambda_reg):\n",
        "    \"\"\"\n",
        "    Compute the cost function with L2 regularization.\n",
        "\n",
        "    Args:\n",
        "        X: Feature matrix with bias term\n",
        "        y: Target labels\n",
        "        theta: Model parameters\n",
        "        lambda_reg: Regularization parameter\n",
        "\n",
        "    Returns:\n",
        "        cost: Regularized cost value\n",
        "    \"\"\"\n",
        "    m = len(y)\n",
        "    h = sigmoid(X @ theta)\n",
        "\n",
        "    # Logistic regression cost\n",
        "    cost = -(1/m) * (y.T @ np.log(h) + (1-y).T @ np.log(1-h))\n",
        "\n",
        "    # Add L2 regularization term (exclude bias term)\n",
        "    reg_term = (lambda_reg / (2 * m)) * np.sum(theta[1:]**2)\n",
        "    cost = cost + reg_term\n",
        "\n",
        "    return cost\n",
        "\n",
        "\n",
        "def gradient_descent(X, y, theta, alpha, num_iters, lambda_reg):\n",
        "    \"\"\"\n",
        "    Perform gradient descent with L2 regularization.\n",
        "\n",
        "    Args:\n",
        "        X: Feature matrix with bias term\n",
        "        y: Target labels\n",
        "        theta: Initial parameters\n",
        "        alpha: Learning rate\n",
        "        num_iters: Number of iterations\n",
        "        lambda_reg: Regularization parameter\n",
        "\n",
        "    Returns:\n",
        "        theta: Optimized parameters\n",
        "        cost_history: List of cost values during training\n",
        "    \"\"\"\n",
        "    m = len(y)\n",
        "    cost_history = []\n",
        "\n",
        "    for i in range(num_iters):\n",
        "        h = sigmoid(X @ theta)\n",
        "        gradient = (1/m) * (X.T @ (h - y))\n",
        "\n",
        "        # Add gradient of regularization term\n",
        "        reg_gradient = (lambda_reg / m) * theta\n",
        "        reg_gradient[0] = 0  # Do not regularize the bias term\n",
        "        gradient += reg_gradient\n",
        "\n",
        "        theta -= alpha * gradient\n",
        "        cost = compute_cost(X, y, theta, lambda_reg)\n",
        "        print(f\"Cost = {cost}\")\n",
        "        cost_history.append(cost)\n",
        "\n",
        "    return theta, cost_history\n",
        "\n",
        "\n",
        "def feature_scaling(X):\n",
        "    \"\"\"Standardize features (z-score normalization).\"\"\"\n",
        "    return (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
        "\n",
        "\n",
        "def load_and_preprocess_data(filepath):\n",
        "    \"\"\"\n",
        "    Load and preprocess the cats vs dogs dataset.\n",
        "\n",
        "    Args:\n",
        "        filepath: Path to the CSV file\n",
        "\n",
        "    Returns:\n",
        "        X_processed: Processed feature matrix with bias term\n",
        "        y_processed: Target labels as column vector\n",
        "        raw_data: Original dataframe\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load the dataset\n",
        "        data = pd.read_csv(filepath)\n",
        "        print(\"Dataset loaded successfully.\")\n",
        "        print(f\"Dataset shape: {data.shape}\")\n",
        "        print(\"\\nFirst 5 rows:\")\n",
        "        print(data.head())\n",
        "\n",
        "        # Separate features and labels (assume last column is the label)\n",
        "        X = data.iloc[:, :-1].values\n",
        "        y = data.iloc[:, -1].values\n",
        "\n",
        "        # Feature scaling\n",
        "        X_scaled = feature_scaling(X)\n",
        "\n",
        "        # Add bias term\n",
        "        X_with_bias = np.c_[np.ones((X_scaled.shape[0], 1)), X_scaled]\n",
        "\n",
        "        # Reshape y to column vector\n",
        "        y_reshaped = y.reshape(-1, 1)\n",
        "\n",
        "        return X_with_bias, y_reshaped, data\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: {filepath} not found.\")\n",
        "        print(\"Please make sure the file exists at the specified path.\")\n",
        "        return None, None, None\n",
        "\n",
        "\n",
        "def train_model(X, y, alpha=0.1, num_iters=1000, lambda_reg=0.01):\n",
        "    \"\"\"\n",
        "    Train the logistic regression model with regularization.\n",
        "\n",
        "    Args:\n",
        "        X: Feature matrix with bias term\n",
        "        y: Target labels\n",
        "        alpha: Learning rate\n",
        "        num_iters: Number of iterations\n",
        "        lambda_reg: Regularization parameter\n",
        "\n",
        "    Returns:\n",
        "        theta: Trained parameters\n",
        "        cost_history: Training cost history\n",
        "    \"\"\"\n",
        "    # Initialize parameters\n",
        "    theta = np.zeros((X.shape[1], 1))\n",
        "\n",
        "    # Train using gradient descent with regularization\n",
        "    theta, cost_history = gradient_descent(X, y, theta, alpha, num_iters, lambda_reg)\n",
        "\n",
        "    print(f\"Training completed!\")\n",
        "    print(f\"Final parameters shape: {theta.shape}\")\n",
        "    # print(f\"Final cost: {cost_history[-1]:.6f}\")\n",
        "\n",
        "    return theta, cost_history\n",
        "\n",
        "\n",
        "def make_predictions(X, theta):\n",
        "    \"\"\"\n",
        "    Make predictions using the trained model.\n",
        "\n",
        "    Args:\n",
        "        X: Feature matrix with bias term\n",
        "        theta: Trained parameters\n",
        "\n",
        "    Returns:\n",
        "        probabilities: Predicted probabilities\n",
        "        predicted_classes: Predicted class labels\n",
        "    \"\"\"\n",
        "    probabilities = sigmoid(X @ theta)\n",
        "    predicted_classes = (probabilities > 0.5).astype(int)\n",
        "\n",
        "    return probabilities, predicted_classes\n",
        "\n",
        "\n",
        "def evaluate_model(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Evaluate model performance.\n",
        "\n",
        "    Args:\n",
        "        y_true: True labels\n",
        "        y_pred: Predicted labels\n",
        "    \"\"\"\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "def plot_cost_history(cost_history, title=\"Cost Function Convergence\"):\n",
        "    \"\"\"Plot the cost function convergence.\"\"\"\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(np.squeeze(cost_history))\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Cost\")\n",
        "    plt.title(title)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "fJfA51uGPQM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Configuration parameters\n",
        "    FILEPATH = '/content/sample_data/catsvsdogs_features_SqueezeNet_1.csv'\n",
        "    LEARNING_RATE = 0.1\n",
        "    NUM_ITERATIONS = 1000\n",
        "    LAMBDA_REG = 0.01\n",
        "    TEST_SIZE = 0.2 # Percentage of data to use for testing\n",
        "\n",
        "    print(\"=== Cats vs Dogs Logistic Regression with Regularization ===\\n\")\n",
        "\n",
        "    # Load and preprocess data\n",
        "    print(\"1. Loading and preprocessing data...\")\n",
        "    X_processed, y_processed, raw_data = load_and_preprocess_data(FILEPATH)\n",
        "\n",
        "    if X_processed is not None:\n",
        "        print(f\"Processed data shape: X={X_processed.shape}, y={y_processed.shape}\")\n",
        "\n",
        "        # Split data into training and testing sets\n",
        "        print(f\"\\n2. Splitting data into training and testing sets (test_size={TEST_SIZE})...\")\n",
        "        from sklearn.model_selection import train_test_split\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X_processed, y_processed, test_size=TEST_SIZE, random_state=42\n",
        "        )\n",
        "        print(f\"Training data shape: X={X_train.shape}, y={y_train.shape}\")\n",
        "        print(f\"Testing data shape: X={X_test.shape}, y={y_test.shape}\")\n",
        "\n",
        "\n",
        "        # Train the model\n",
        "        print(f\"\\n3. Training model...\")\n",
        "        print(f\"   Learning rate: {LEARNING_RATE}\")\n",
        "        print(f\"   Iterations: {NUM_ITERATIONS}\")\n",
        "        print(f\"   Regularization parameter: {LAMBDA_REG}\")\n",
        "\n",
        "        theta_trained, cost_history = train_model(\n",
        "            X_train, y_train, # Use training data for training\n",
        "            alpha=LEARNING_RATE,\n",
        "            num_iters=NUM_ITERATIONS,\n",
        "            lambda_reg=LAMBDA_REG\n",
        "        )\n",
        "\n",
        "        # Plot training progress\n",
        "        print(\"\\n4. Plotting training progress...\")\n",
        "        plot_cost_history(cost_history, \"Cost Function Convergence (Training Data)\")\n",
        "\n",
        "        # Make predictions on the test set\n",
        "        print(\"\\n5. Making predictions on the test set...\")\n",
        "        probabilities_test, predicted_classes_test = make_predictions(X_test, theta_trained)\n",
        "\n",
        "        print(f\"First 5 predictions on test set (probabilities):\")\n",
        "        print(probabilities_test[:5].flatten())\n",
        "        print(f\"First 5 predicted classes on test set:\")\n",
        "        print(predicted_classes_test[:5].flatten())\n",
        "\n",
        "\n",
        "        # Evaluate model on the test set\n",
        "        print(\"\\n6. Evaluating model performance on the test set...\")\n",
        "        print(\"--- Test Set Evaluation ---\")\n",
        "        accuracy_test = evaluate_model(y_test, predicted_classes_test)\n",
        "\n",
        "        # Make predictions on the training set and evaluate\n",
        "        print(\"\\n--- Training Set Evaluation ---\")\n",
        "        probabilities_train, predicted_classes_train = make_predictions(X_train, theta_trained)\n",
        "        accuracy_train = evaluate_model(y_train, predicted_classes_train)\n",
        "\n",
        "\n",
        "        print(f\"\\n=== Training and Evaluation Summary ===\")\n",
        "        print(f\"Dataset: {raw_data.shape[0]} samples, {raw_data.shape[1]-1} features\")\n",
        "        print(f\"Training samples: {X_train.shape[0]}\")\n",
        "        print(f\"Testing samples: {X_test.shape[0]}\")\n",
        "        print(f\"Final training accuracy: {accuracy_train:.4f}\")\n",
        "        print(f\"Final test accuracy: {accuracy_test:.4f}\")\n",
        "        # Note: The cost history and final cost are based on the training data.\n",
        "        # Using .item() to handle potential numpy array with single value\n",
        "        if cost_history and isinstance(cost_history[-1], np.ndarray) and cost_history[-1].size == 1:\n",
        "            print(f\"Final training cost: {cost_history[-1].item():.6f}\")\n",
        "        elif cost_history:\n",
        "             print(f\"Final training cost: {cost_history[-1]:.6f}\")\n",
        "        print(f\"Model trained and evaluated successfully!\")\n",
        "\n",
        "    else:\n",
        "        print(\"Failed to load data. Please check the file path and try again.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nmkPPFVwPa20",
        "outputId": "f5994d9b-a5c2-470d-a5b4-d50259599cb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Cats vs Dogs Logistic Regression with Regularization ===\n",
            "\n",
            "1. Loading and preprocessing data...\n",
            "Dataset loaded successfully.\n",
            "Dataset shape: (11632, 514)\n",
            "\n",
            "First 5 rows:\n",
            "   0   0.364  2.496  0.269    0.0   1.936  0.0.1  2.474  0.078  9.922  ...  \\\n",
            "0  1   0.826  6.313  0.000  1.050   2.799  0.253  2.210  2.462  2.055  ...   \n",
            "1  2   0.096  8.977  0.034  0.642  14.419  0.191  0.359  1.011  3.403  ...   \n",
            "2  3  10.767  1.540  0.836  1.429   2.764  0.000  3.294  0.724  0.899  ...   \n",
            "3  4   1.738  1.957  0.920  0.907   1.318  0.073  0.936  1.102  0.761  ...   \n",
            "4  5   2.452  1.567  7.992  2.290   4.671  0.452  0.763  0.461  2.001  ...   \n",
            "\n",
            "   11.256  3.955  4.388  8.537   0.02   2.277  4.903  0.381   7.209  1.0  \n",
            "0   2.202  0.000  0.369  0.000  0.000   1.594  0.024  3.787   7.847  1.0  \n",
            "1   0.065  0.135  4.759  0.706  0.000   0.832  0.000  1.697   0.103  1.0  \n",
            "2   3.799  2.047  6.838  0.543  5.967   3.367  4.987  1.541   7.214  0.0  \n",
            "3   3.161  2.924  6.030  0.992  0.848   2.457  0.000  0.579  26.182  1.0  \n",
            "4   3.063  3.692  1.103  7.223  0.307  14.411  3.001  1.051   5.289  1.0  \n",
            "\n",
            "[5 rows x 514 columns]\n",
            "Processed data shape: X=(11632, 514), y=(11632, 1)\n",
            "\n",
            "2. Splitting data into training and testing sets (test_size=0.2)...\n",
            "Training data shape: X=(9305, 514), y=(9305, 1)\n",
            "Testing data shape: X=(2327, 514), y=(2327, 1)\n",
            "\n",
            "3. Training model...\n",
            "   Learning rate: 0.1\n",
            "   Iterations: 1000\n",
            "   Regularization parameter: 0.01\n",
            "Cost = [[0.38529445]]\n",
            "Cost = [[0.30690392]]\n",
            "Cost = [[0.26656071]]\n",
            "Cost = [[0.24095561]]\n",
            "Cost = [[0.22288976]]\n",
            "Cost = [[0.20928571]]\n",
            "Cost = [[0.19857582]]\n",
            "Cost = [[0.18986659]]\n",
            "Cost = [[0.1826069]]\n",
            "Cost = [[0.17643616]]\n",
            "Cost = [[0.17110744]]\n",
            "Cost = [[0.16644531]]\n",
            "Cost = [[0.16232132]]\n",
            "Cost = [[0.15863904]]\n",
            "Cost = [[0.1553245]]\n",
            "Cost = [[0.15231993]]\n",
            "Cost = [[0.14957945]]\n",
            "Cost = [[0.14706613]]\n",
            "Cost = [[0.14474988]]\n",
            "Cost = [[0.14260588]]\n",
            "Cost = [[0.14061348]]\n",
            "Cost = [[0.13875532]]\n",
            "Cost = [[0.13701672]]\n",
            "Cost = [[0.13538514]]\n",
            "Cost = [[0.13384979]]\n",
            "Cost = [[0.13240139]]\n",
            "Cost = [[0.13103182]]\n",
            "Cost = [[0.129734]]\n",
            "Cost = [[0.12850174]]\n",
            "Cost = [[0.12732953]]\n",
            "Cost = [[0.12621251]]\n",
            "Cost = [[0.12514636]]\n",
            "Cost = [[0.12412721]]\n",
            "Cost = [[0.1231516]]\n",
            "Cost = [[0.12221641]]\n",
            "Cost = [[0.12131882]]\n",
            "Cost = [[0.1204563]]\n",
            "Cost = [[0.11962653]]\n",
            "Cost = [[0.11882741]]\n",
            "Cost = [[0.11805703]]\n",
            "Cost = [[0.11731364]]\n",
            "Cost = [[0.11659564]]\n",
            "Cost = [[0.11590154]]\n",
            "Cost = [[0.11522999]]\n",
            "Cost = [[0.11457974]]\n",
            "Cost = [[0.11394965]]\n",
            "Cost = [[0.11333863]]\n",
            "Cost = [[0.1127457]]\n",
            "Cost = [[0.11216994]]\n",
            "Cost = [[0.1116105]]\n",
            "Cost = [[0.11106658]]\n",
            "Cost = [[0.11053743]]\n",
            "Cost = [[0.11002237]]\n",
            "Cost = [[0.10952074]]\n",
            "Cost = [[0.10903194]]\n",
            "Cost = [[0.1085554]]\n",
            "Cost = [[0.10809059]]\n",
            "Cost = [[0.107637]]\n",
            "Cost = [[0.10719416]]\n",
            "Cost = [[0.10676163]]\n",
            "Cost = [[0.10633899]]\n",
            "Cost = [[0.10592585]]\n",
            "Cost = [[0.10552182]]\n",
            "Cost = [[0.10512657]]\n",
            "Cost = [[0.10473974]]\n",
            "Cost = [[0.10436104]]\n",
            "Cost = [[0.10399015]]\n",
            "Cost = [[0.1036268]]\n",
            "Cost = [[0.10327071]]\n",
            "Cost = [[0.10292163]]\n",
            "Cost = [[0.10257932]]\n",
            "Cost = [[0.10224353]]\n",
            "Cost = [[0.10191406]]\n",
            "Cost = [[0.10159069]]\n",
            "Cost = [[0.10127323]]\n",
            "Cost = [[0.10096147]]\n",
            "Cost = [[0.10065523]]\n",
            "Cost = [[0.10035436]]\n",
            "Cost = [[0.10005866]]\n",
            "Cost = [[0.099768]]\n",
            "Cost = [[0.0994822]]\n",
            "Cost = [[0.09920114]]\n",
            "Cost = [[0.09892466]]\n",
            "Cost = [[0.09865263]]\n",
            "Cost = [[0.09838493]]\n",
            "Cost = [[0.09812144]]\n",
            "Cost = [[0.09786202]]\n",
            "Cost = [[0.09760658]]\n",
            "Cost = [[0.09735499]]\n",
            "Cost = [[0.09710716]]\n",
            "Cost = [[0.09686299]]\n",
            "Cost = [[0.09662237]]\n",
            "Cost = [[0.09638521]]\n",
            "Cost = [[0.09615143]]\n",
            "Cost = [[0.09592093]]\n",
            "Cost = [[0.09569364]]\n",
            "Cost = [[0.09546947]]\n",
            "Cost = [[0.09524834]]\n",
            "Cost = [[0.09503019]]\n",
            "Cost = [[0.09481493]]\n",
            "Cost = [[0.09460249]]\n",
            "Cost = [[0.09439282]]\n",
            "Cost = [[0.09418584]]\n",
            "Cost = [[0.09398149]]\n",
            "Cost = [[0.09377971]]\n",
            "Cost = [[0.09358045]]\n",
            "Cost = [[0.09338364]]\n",
            "Cost = [[0.09318923]]\n",
            "Cost = [[0.09299716]]\n",
            "Cost = [[0.09280739]]\n",
            "Cost = [[0.09261986]]\n",
            "Cost = [[0.09243453]]\n",
            "Cost = [[0.09225134]]\n",
            "Cost = [[0.09207026]]\n",
            "Cost = [[0.09189124]]\n",
            "Cost = [[0.09171423]]\n",
            "Cost = [[0.09153919]]\n",
            "Cost = [[0.09136609]]\n",
            "Cost = [[0.09119489]]\n",
            "Cost = [[0.09102554]]\n",
            "Cost = [[0.090858]]\n",
            "Cost = [[0.09069226]]\n",
            "Cost = [[0.09052826]]\n",
            "Cost = [[0.09036597]]\n",
            "Cost = [[0.09020537]]\n",
            "Cost = [[0.09004641]]\n",
            "Cost = [[0.08988907]]\n",
            "Cost = [[0.08973332]]\n",
            "Cost = [[0.08957913]]\n",
            "Cost = [[0.08942647]]\n",
            "Cost = [[0.08927531]]\n",
            "Cost = [[0.08912562]]\n",
            "Cost = [[0.08897738]]\n",
            "Cost = [[0.08883056]]\n",
            "Cost = [[0.08868514]]\n",
            "Cost = [[0.08854109]]\n",
            "Cost = [[0.08839838]]\n",
            "Cost = [[0.088257]]\n",
            "Cost = [[0.08811693]]\n",
            "Cost = [[0.08797813]]\n",
            "Cost = [[0.08784059]]\n",
            "Cost = [[0.08770429]]\n",
            "Cost = [[0.0875692]]\n",
            "Cost = [[0.08743531]]\n",
            "Cost = [[0.08730259]]\n",
            "Cost = [[0.08717103]]\n",
            "Cost = [[0.08704061]]\n",
            "Cost = [[0.08691131]]\n",
            "Cost = [[0.08678312]]\n",
            "Cost = [[0.086656]]\n",
            "Cost = [[0.08652996]]\n",
            "Cost = [[0.08640496]]\n",
            "Cost = [[0.086281]]\n",
            "Cost = [[0.08615806]]\n",
            "Cost = [[0.08603613]]\n",
            "Cost = [[0.08591518]]\n",
            "Cost = [[0.0857952]]\n",
            "Cost = [[0.08567618]]\n",
            "Cost = [[0.08555811]]\n",
            "Cost = [[0.08544096]]\n",
            "Cost = [[0.08532474]]\n",
            "Cost = [[0.08520942]]\n",
            "Cost = [[0.08509498]]\n",
            "Cost = [[0.08498143]]\n",
            "Cost = [[0.08486874]]\n",
            "Cost = [[0.0847569]]\n",
            "Cost = [[0.0846459]]\n",
            "Cost = [[0.08453573]]\n",
            "Cost = [[0.08442638]]\n",
            "Cost = [[0.08431784]]\n",
            "Cost = [[0.08421009]]\n",
            "Cost = [[0.08410313]]\n",
            "Cost = [[0.08399693]]\n",
            "Cost = [[0.08389151]]\n",
            "Cost = [[0.08378683]]\n",
            "Cost = [[0.0836829]]\n",
            "Cost = [[0.0835797]]\n",
            "Cost = [[0.08347722]]\n",
            "Cost = [[0.08337546]]\n",
            "Cost = [[0.0832744]]\n",
            "Cost = [[0.08317404]]\n",
            "Cost = [[0.08307436]]\n",
            "Cost = [[0.08297537]]\n",
            "Cost = [[0.08287704]]\n",
            "Cost = [[0.08277937]]\n",
            "Cost = [[0.08268236]]\n",
            "Cost = [[0.08258599]]\n",
            "Cost = [[0.08249025]]\n",
            "Cost = [[0.08239515]]\n",
            "Cost = [[0.08230067]]\n",
            "Cost = [[0.0822068]]\n",
            "Cost = [[0.08211353]]\n",
            "Cost = [[0.08202087]]\n",
            "Cost = [[0.08192879]]\n",
            "Cost = [[0.0818373]]\n",
            "Cost = [[0.08174639]]\n",
            "Cost = [[0.08165605]]\n",
            "Cost = [[0.08156627]]\n",
            "Cost = [[0.08147705]]\n",
            "Cost = [[0.08138838]]\n",
            "Cost = [[0.08130026]]\n",
            "Cost = [[0.08121268]]\n",
            "Cost = [[0.08112562]]\n",
            "Cost = [[0.0810391]]\n",
            "Cost = [[0.08095309]]\n",
            "Cost = [[0.0808676]]\n",
            "Cost = [[0.08078262]]\n",
            "Cost = [[0.08069814]]\n",
            "Cost = [[0.08061416]]\n",
            "Cost = [[0.08053067]]\n",
            "Cost = [[0.08044767]]\n",
            "Cost = [[0.08036515]]\n",
            "Cost = [[0.0802831]]\n",
            "Cost = [[0.08020153]]\n",
            "Cost = [[0.08012042]]\n",
            "Cost = [[0.08003978]]\n",
            "Cost = [[0.07995959]]\n",
            "Cost = [[0.07987985]]\n",
            "Cost = [[0.07980056]]\n",
            "Cost = [[0.07972171]]\n",
            "Cost = [[0.0796433]]\n",
            "Cost = [[0.07956532]]\n",
            "Cost = [[0.07948778]]\n",
            "Cost = [[0.07941065]]\n",
            "Cost = [[0.07933395]]\n",
            "Cost = [[0.07925766]]\n",
            "Cost = [[0.07918178]]\n",
            "Cost = [[0.07910631]]\n",
            "Cost = [[0.07903124]]\n",
            "Cost = [[0.07895658]]\n",
            "Cost = [[0.0788823]]\n",
            "Cost = [[0.07880842]]\n",
            "Cost = [[0.07873493]]\n",
            "Cost = [[0.07866182]]\n",
            "Cost = [[0.07858909]]\n",
            "Cost = [[0.07851674]]\n",
            "Cost = [[0.07844476]]\n",
            "Cost = [[0.07837315]]\n",
            "Cost = [[0.07830191]]\n",
            "Cost = [[0.07823102]]\n",
            "Cost = [[0.0781605]]\n",
            "Cost = [[0.07809033]]\n",
            "Cost = [[0.07802052]]\n",
            "Cost = [[0.07795105]]\n",
            "Cost = [[0.07788193]]\n",
            "Cost = [[0.07781315]]\n",
            "Cost = [[0.07774471]]\n",
            "Cost = [[0.07767661]]\n",
            "Cost = [[0.07760884]]\n",
            "Cost = [[0.0775414]]\n",
            "Cost = [[0.07747429]]\n",
            "Cost = [[0.0774075]]\n",
            "Cost = [[0.07734103]]\n",
            "Cost = [[0.07727488]]\n",
            "Cost = [[0.07720905]]\n",
            "Cost = [[0.07714353]]\n",
            "Cost = [[0.07707832]]\n",
            "Cost = [[0.07701342]]\n",
            "Cost = [[0.07694882]]\n",
            "Cost = [[0.07688453]]\n",
            "Cost = [[0.07682053]]\n",
            "Cost = [[0.07675683]]\n",
            "Cost = [[0.07669343]]\n",
            "Cost = [[0.07663032]]\n",
            "Cost = [[0.07656749]]\n",
            "Cost = [[0.07650496]]\n",
            "Cost = [[0.0764427]]\n",
            "Cost = [[0.07638073]]\n",
            "Cost = [[0.07631904]]\n",
            "Cost = [[0.07625763]]\n",
            "Cost = [[0.07619649]]\n",
            "Cost = [[0.07613563]]\n",
            "Cost = [[0.07607503]]\n",
            "Cost = [[0.07601471]]\n",
            "Cost = [[0.07595465]]\n",
            "Cost = [[0.07589485]]\n",
            "Cost = [[0.07583532]]\n",
            "Cost = [[0.07577604]]\n",
            "Cost = [[0.07571703]]\n",
            "Cost = [[0.07565826]]\n",
            "Cost = [[0.07559976]]\n",
            "Cost = [[0.0755415]]\n",
            "Cost = [[0.07548349]]\n",
            "Cost = [[0.07542573]]\n",
            "Cost = [[0.07536822]]\n",
            "Cost = [[0.07531095]]\n",
            "Cost = [[0.07525392]]\n",
            "Cost = [[0.07519713]]\n",
            "Cost = [[0.07514058]]\n",
            "Cost = [[0.07508427]]\n",
            "Cost = [[0.07502819]]\n",
            "Cost = [[0.07497234]]\n",
            "Cost = [[0.07491672]]\n",
            "Cost = [[0.07486134]]\n",
            "Cost = [[0.07480618]]\n",
            "Cost = [[0.07475124]]\n",
            "Cost = [[0.07469653]]\n",
            "Cost = [[0.07464204]]\n",
            "Cost = [[0.07458778]]\n",
            "Cost = [[0.07453373]]\n",
            "Cost = [[0.07447989]]\n",
            "Cost = [[0.07442628]]\n",
            "Cost = [[0.07437288]]\n",
            "Cost = [[0.07431969]]\n",
            "Cost = [[0.07426671]]\n",
            "Cost = [[0.07421394]]\n",
            "Cost = [[0.07416138]]\n",
            "Cost = [[0.07410902]]\n",
            "Cost = [[0.07405687]]\n",
            "Cost = [[0.07400493]]\n",
            "Cost = [[0.07395318]]\n",
            "Cost = [[0.07390164]]\n",
            "Cost = [[0.07385029]]\n",
            "Cost = [[0.07379915]]\n",
            "Cost = [[0.0737482]]\n",
            "Cost = [[0.07369744]]\n",
            "Cost = [[0.07364688]]\n",
            "Cost = [[0.07359651]]\n",
            "Cost = [[0.07354633]]\n",
            "Cost = [[0.07349634]]\n",
            "Cost = [[0.07344654]]\n",
            "Cost = [[0.07339692]]\n",
            "Cost = [[0.07334749]]\n",
            "Cost = [[0.07329825]]\n",
            "Cost = [[0.07324919]]\n",
            "Cost = [[0.07320031]]\n",
            "Cost = [[0.07315161]]\n",
            "Cost = [[0.07310309]]\n",
            "Cost = [[0.07305475]]\n",
            "Cost = [[0.07300658]]\n",
            "Cost = [[0.07295859]]\n",
            "Cost = [[0.07291078]]\n",
            "Cost = [[0.07286314]]\n",
            "Cost = [[0.07281567]]\n",
            "Cost = [[0.07276837]]\n",
            "Cost = [[0.07272124]]\n",
            "Cost = [[0.07267429]]\n",
            "Cost = [[0.0726275]]\n",
            "Cost = [[0.07258087]]\n",
            "Cost = [[0.07253441]]\n",
            "Cost = [[0.07248812]]\n",
            "Cost = [[0.07244199]]\n",
            "Cost = [[0.07239602]]\n",
            "Cost = [[0.07235022]]\n",
            "Cost = [[0.07230457]]\n",
            "Cost = [[0.07225908]]\n",
            "Cost = [[0.07221375]]\n",
            "Cost = [[0.07216858]]\n",
            "Cost = [[0.07212357]]\n",
            "Cost = [[0.07207871]]\n",
            "Cost = [[0.072034]]\n",
            "Cost = [[0.07198945]]\n",
            "Cost = [[0.07194505]]\n",
            "Cost = [[0.07190081]]\n",
            "Cost = [[0.07185671]]\n",
            "Cost = [[0.07181276]]\n",
            "Cost = [[0.07176896]]\n",
            "Cost = [[0.07172531]]\n",
            "Cost = [[0.0716818]]\n",
            "Cost = [[0.07163845]]\n",
            "Cost = [[0.07159523]]\n",
            "Cost = [[0.07155216]]\n",
            "Cost = [[0.07150924]]\n",
            "Cost = [[0.07146645]]\n",
            "Cost = [[0.07142381]]\n",
            "Cost = [[0.07138131]]\n",
            "Cost = [[0.07133895]]\n",
            "Cost = [[0.07129672]]\n",
            "Cost = [[0.07125464]]\n",
            "Cost = [[0.07121269]]\n",
            "Cost = [[0.07117088]]\n",
            "Cost = [[0.0711292]]\n",
            "Cost = [[0.07108766]]\n",
            "Cost = [[0.07104626]]\n",
            "Cost = [[0.07100499]]\n",
            "Cost = [[0.07096385]]\n",
            "Cost = [[0.07092284]]\n",
            "Cost = [[0.07088196]]\n",
            "Cost = [[0.07084121]]\n",
            "Cost = [[0.07080059]]\n",
            "Cost = [[0.07076011]]\n",
            "Cost = [[0.07071974]]\n",
            "Cost = [[0.07067951]]\n",
            "Cost = [[0.0706394]]\n",
            "Cost = [[0.07059942]]\n",
            "Cost = [[0.07055957]]\n",
            "Cost = [[0.07051983]]\n",
            "Cost = [[0.07048022]]\n",
            "Cost = [[0.07044074]]\n",
            "Cost = [[0.07040138]]\n",
            "Cost = [[0.07036213]]\n",
            "Cost = [[0.07032301]]\n",
            "Cost = [[0.07028401]]\n",
            "Cost = [[0.07024513]]\n",
            "Cost = [[0.07020637]]\n",
            "Cost = [[0.07016773]]\n",
            "Cost = [[0.0701292]]\n",
            "Cost = [[0.07009079]]\n",
            "Cost = [[0.0700525]]\n",
            "Cost = [[0.07001432]]\n",
            "Cost = [[0.06997626]]\n",
            "Cost = [[0.06993831]]\n",
            "Cost = [[0.06990048]]\n",
            "Cost = [[0.06986276]]\n",
            "Cost = [[0.06982515]]\n",
            "Cost = [[0.06978765]]\n",
            "Cost = [[0.06975027]]\n",
            "Cost = [[0.06971299]]\n",
            "Cost = [[0.06967583]]\n",
            "Cost = [[0.06963877]]\n",
            "Cost = [[0.06960183]]\n",
            "Cost = [[0.06956499]]\n",
            "Cost = [[0.06952826]]\n",
            "Cost = [[0.06949163]]\n",
            "Cost = [[0.06945512]]\n",
            "Cost = [[0.06941871]]\n",
            "Cost = [[0.0693824]]\n",
            "Cost = [[0.0693462]]\n",
            "Cost = [[0.06931011]]\n",
            "Cost = [[0.06927412]]\n",
            "Cost = [[0.06923823]]\n",
            "Cost = [[0.06920244]]\n",
            "Cost = [[0.06916676]]\n",
            "Cost = [[0.06913118]]\n",
            "Cost = [[0.0690957]]\n",
            "Cost = [[0.06906032]]\n",
            "Cost = [[0.06902504]]\n",
            "Cost = [[0.06898986]]\n",
            "Cost = [[0.06895478]]\n",
            "Cost = [[0.0689198]]\n",
            "Cost = [[0.06888492]]\n",
            "Cost = [[0.06885013]]\n",
            "Cost = [[0.06881544]]\n",
            "Cost = [[0.06878085]]\n",
            "Cost = [[0.06874635]]\n",
            "Cost = [[0.06871195]]\n",
            "Cost = [[0.06867765]]\n",
            "Cost = [[0.06864344]]\n",
            "Cost = [[0.06860932]]\n",
            "Cost = [[0.0685753]]\n",
            "Cost = [[0.06854137]]\n",
            "Cost = [[0.06850753]]\n",
            "Cost = [[0.06847379]]\n",
            "Cost = [[0.06844014]]\n",
            "Cost = [[0.06840658]]\n",
            "Cost = [[0.06837311]]\n",
            "Cost = [[0.06833973]]\n",
            "Cost = [[0.06830644]]\n",
            "Cost = [[0.06827324]]\n",
            "Cost = [[0.06824013]]\n",
            "Cost = [[0.06820711]]\n",
            "Cost = [[0.06817418]]\n",
            "Cost = [[0.06814133]]\n",
            "Cost = [[0.06810858]]\n",
            "Cost = [[0.06807591]]\n",
            "Cost = [[0.06804332]]\n",
            "Cost = [[0.06801083]]\n",
            "Cost = [[0.06797841]]\n",
            "Cost = [[0.06794609]]\n",
            "Cost = [[0.06791385]]\n",
            "Cost = [[0.06788169]]\n",
            "Cost = [[0.06784962]]\n",
            "Cost = [[0.06781763]]\n",
            "Cost = [[0.06778573]]\n",
            "Cost = [[0.06775391]]\n",
            "Cost = [[0.06772217]]\n",
            "Cost = [[0.06769051]]\n",
            "Cost = [[0.06765894]]\n",
            "Cost = [[0.06762745]]\n",
            "Cost = [[0.06759603]]\n",
            "Cost = [[0.0675647]]\n",
            "Cost = [[0.06753345]]\n",
            "Cost = [[0.06750228]]\n",
            "Cost = [[0.06747119]]\n",
            "Cost = [[0.06744018]]\n",
            "Cost = [[0.06740925]]\n",
            "Cost = [[0.06737839]]\n",
            "Cost = [[0.06734762]]\n",
            "Cost = [[0.06731692]]\n",
            "Cost = [[0.0672863]]\n",
            "Cost = [[0.06725576]]\n",
            "Cost = [[0.06722529]]\n",
            "Cost = [[0.0671949]]\n",
            "Cost = [[0.06716458]]\n",
            "Cost = [[0.06713435]]\n",
            "Cost = [[0.06710418]]\n",
            "Cost = [[0.0670741]]\n",
            "Cost = [[0.06704408]]\n",
            "Cost = [[0.06701414]]\n",
            "Cost = [[0.06698428]]\n",
            "Cost = [[0.06695449]]\n",
            "Cost = [[0.06692477]]\n",
            "Cost = [[0.06689513]]\n",
            "Cost = [[0.06686555]]\n",
            "Cost = [[0.06683605]]\n",
            "Cost = [[0.06680663]]\n",
            "Cost = [[0.06677727]]\n",
            "Cost = [[0.06674799]]\n",
            "Cost = [[0.06671878]]\n",
            "Cost = [[0.06668963]]\n",
            "Cost = [[0.06666056]]\n",
            "Cost = [[0.06663156]]\n",
            "Cost = [[0.06660263]]\n",
            "Cost = [[0.06657377]]\n",
            "Cost = [[0.06654498]]\n",
            "Cost = [[0.06651625]]\n",
            "Cost = [[0.0664876]]\n",
            "Cost = [[0.06645901]]\n",
            "Cost = [[0.0664305]]\n",
            "Cost = [[0.06640205]]\n",
            "Cost = [[0.06637366]]\n",
            "Cost = [[0.06634535]]\n",
            "Cost = [[0.0663171]]\n",
            "Cost = [[0.06628892]]\n",
            "Cost = [[0.06626081]]\n",
            "Cost = [[0.06623276]]\n",
            "Cost = [[0.06620477]]\n",
            "Cost = [[0.06617686]]\n",
            "Cost = [[0.066149]]\n",
            "Cost = [[0.06612122]]\n",
            "Cost = [[0.06609349]]\n",
            "Cost = [[0.06606584]]\n",
            "Cost = [[0.06603824]]\n",
            "Cost = [[0.06601071]]\n",
            "Cost = [[0.06598325]]\n",
            "Cost = [[0.06595585]]\n",
            "Cost = [[0.06592851]]\n",
            "Cost = [[0.06590123]]\n",
            "Cost = [[0.06587402]]\n",
            "Cost = [[0.06584687]]\n",
            "Cost = [[0.06581978]]\n",
            "Cost = [[0.06579275]]\n",
            "Cost = [[0.06576578]]\n",
            "Cost = [[0.06573888]]\n",
            "Cost = [[0.06571204]]\n",
            "Cost = [[0.06568525]]\n",
            "Cost = [[0.06565853]]\n",
            "Cost = [[0.06563187]]\n",
            "Cost = [[0.06560527]]\n",
            "Cost = [[0.06557873]]\n",
            "Cost = [[0.06555225]]\n",
            "Cost = [[0.06552582]]\n",
            "Cost = [[0.06549946]]\n",
            "Cost = [[0.06547316]]\n",
            "Cost = [[0.06544691]]\n",
            "Cost = [[0.06542072]]\n",
            "Cost = [[0.0653946]]\n",
            "Cost = [[0.06536852]]\n",
            "Cost = [[0.06534251]]\n",
            "Cost = [[0.06531656]]\n",
            "Cost = [[0.06529066]]\n",
            "Cost = [[0.06526482]]\n",
            "Cost = [[0.06523903]]\n",
            "Cost = [[0.0652133]]\n",
            "Cost = [[0.06518763]]\n",
            "Cost = [[0.06516202]]\n",
            "Cost = [[0.06513646]]\n",
            "Cost = [[0.06511096]]\n",
            "Cost = [[0.06508551]]\n",
            "Cost = [[0.06506012]]\n",
            "Cost = [[0.06503478]]\n",
            "Cost = [[0.0650095]]\n",
            "Cost = [[0.06498427]]\n",
            "Cost = [[0.06495909]]\n",
            "Cost = [[0.06493397]]\n",
            "Cost = [[0.06490891]]\n",
            "Cost = [[0.0648839]]\n",
            "Cost = [[0.06485894]]\n",
            "Cost = [[0.06483404]]\n",
            "Cost = [[0.06480919]]\n",
            "Cost = [[0.06478439]]\n",
            "Cost = [[0.06475964]]\n",
            "Cost = [[0.06473495]]\n",
            "Cost = [[0.06471031]]\n",
            "Cost = [[0.06468572]]\n",
            "Cost = [[0.06466119]]\n",
            "Cost = [[0.0646367]]\n",
            "Cost = [[0.06461227]]\n",
            "Cost = [[0.06458789]]\n",
            "Cost = [[0.06456356]]\n",
            "Cost = [[0.06453928]]\n",
            "Cost = [[0.06451505]]\n",
            "Cost = [[0.06449087]]\n",
            "Cost = [[0.06446675]]\n",
            "Cost = [[0.06444267]]\n",
            "Cost = [[0.06441864]]\n",
            "Cost = [[0.06439467]]\n",
            "Cost = [[0.06437074]]\n",
            "Cost = [[0.06434686]]\n",
            "Cost = [[0.06432303]]\n",
            "Cost = [[0.06429926]]\n",
            "Cost = [[0.06427553]]\n",
            "Cost = [[0.06425184]]\n",
            "Cost = [[0.06422821]]\n",
            "Cost = [[0.06420463]]\n",
            "Cost = [[0.06418109]]\n",
            "Cost = [[0.06415761]]\n",
            "Cost = [[0.06413417]]\n",
            "Cost = [[0.06411077]]\n",
            "Cost = [[0.06408743]]\n",
            "Cost = [[0.06406413]]\n",
            "Cost = [[0.06404088]]\n",
            "Cost = [[0.06401768]]\n",
            "Cost = [[0.06399452]]\n",
            "Cost = [[0.06397142]]\n",
            "Cost = [[0.06394835]]\n",
            "Cost = [[0.06392534]]\n",
            "Cost = [[0.06390237]]\n",
            "Cost = [[0.06387944]]\n",
            "Cost = [[0.06385657]]\n",
            "Cost = [[0.06383373]]\n",
            "Cost = [[0.06381095]]\n",
            "Cost = [[0.06378821]]\n",
            "Cost = [[0.06376551]]\n",
            "Cost = [[0.06374286]]\n",
            "Cost = [[0.06372025]]\n",
            "Cost = [[0.06369769]]\n",
            "Cost = [[0.06367517]]\n",
            "Cost = [[0.0636527]]\n",
            "Cost = [[0.06363027]]\n",
            "Cost = [[0.06360789]]\n",
            "Cost = [[0.06358555]]\n",
            "Cost = [[0.06356326]]\n",
            "Cost = [[0.063541]]\n",
            "Cost = [[0.06351879]]\n",
            "Cost = [[0.06349663]]\n",
            "Cost = [[0.06347451]]\n",
            "Cost = [[0.06345243]]\n",
            "Cost = [[0.06343039]]\n",
            "Cost = [[0.0634084]]\n",
            "Cost = [[0.06338645]]\n",
            "Cost = [[0.06336454]]\n",
            "Cost = [[0.06334267]]\n",
            "Cost = [[0.06332085]]\n",
            "Cost = [[0.06329907]]\n",
            "Cost = [[0.06327733]]\n",
            "Cost = [[0.06325563]]\n",
            "Cost = [[0.06323397]]\n",
            "Cost = [[0.06321236]]\n",
            "Cost = [[0.06319078]]\n",
            "Cost = [[0.06316925]]\n",
            "Cost = [[0.06314776]]\n",
            "Cost = [[0.06312631]]\n",
            "Cost = [[0.0631049]]\n",
            "Cost = [[0.06308353]]\n",
            "Cost = [[0.0630622]]\n",
            "Cost = [[0.06304091]]\n",
            "Cost = [[0.06301966]]\n",
            "Cost = [[0.06299846]]\n",
            "Cost = [[0.06297729]]\n",
            "Cost = [[0.06295616]]\n",
            "Cost = [[0.06293507]]\n",
            "Cost = [[0.06291402]]\n",
            "Cost = [[0.06289301]]\n",
            "Cost = [[0.06287204]]\n",
            "Cost = [[0.06285111]]\n",
            "Cost = [[0.06283022]]\n",
            "Cost = [[0.06280937]]\n",
            "Cost = [[0.06278855]]\n",
            "Cost = [[0.06276778]]\n",
            "Cost = [[0.06274704]]\n",
            "Cost = [[0.06272634]]\n",
            "Cost = [[0.06270568]]\n",
            "Cost = [[0.06268506]]\n",
            "Cost = [[0.06266447]]\n",
            "Cost = [[0.06264392]]\n",
            "Cost = [[0.06262342]]\n",
            "Cost = [[0.06260294]]\n",
            "Cost = [[0.06258251]]\n",
            "Cost = [[0.06256211]]\n",
            "Cost = [[0.06254175]]\n",
            "Cost = [[0.06252143]]\n",
            "Cost = [[0.06250115]]\n",
            "Cost = [[0.0624809]]\n",
            "Cost = [[0.06246069]]\n",
            "Cost = [[0.06244051]]\n",
            "Cost = [[0.06242038]]\n",
            "Cost = [[0.06240027]]\n",
            "Cost = [[0.06238021]]\n",
            "Cost = [[0.06236018]]\n",
            "Cost = [[0.06234019]]\n",
            "Cost = [[0.06232023]]\n",
            "Cost = [[0.06230031]]\n",
            "Cost = [[0.06228042]]\n",
            "Cost = [[0.06226057]]\n",
            "Cost = [[0.06224076]]\n",
            "Cost = [[0.06222098]]\n",
            "Cost = [[0.06220124]]\n",
            "Cost = [[0.06218153]]\n",
            "Cost = [[0.06216185]]\n",
            "Cost = [[0.06214222]]\n",
            "Cost = [[0.06212261]]\n",
            "Cost = [[0.06210304]]\n",
            "Cost = [[0.06208351]]\n",
            "Cost = [[0.06206401]]\n",
            "Cost = [[0.06204454]]\n",
            "Cost = [[0.06202511]]\n",
            "Cost = [[0.06200572]]\n",
            "Cost = [[0.06198635]]\n",
            "Cost = [[0.06196703]]\n",
            "Cost = [[0.06194773]]\n",
            "Cost = [[0.06192847]]\n",
            "Cost = [[0.06190924]]\n",
            "Cost = [[0.06189005]]\n",
            "Cost = [[0.06187089]]\n",
            "Cost = [[0.06185176]]\n",
            "Cost = [[0.06183267]]\n",
            "Cost = [[0.06181361]]\n",
            "Cost = [[0.06179458]]\n",
            "Cost = [[0.06177558]]\n",
            "Cost = [[0.06175662]]\n",
            "Cost = [[0.06173769]]\n",
            "Cost = [[0.0617188]]\n",
            "Cost = [[0.06169993]]\n",
            "Cost = [[0.0616811]]\n",
            "Cost = [[0.0616623]]\n",
            "Cost = [[0.06164354]]\n",
            "Cost = [[0.0616248]]\n",
            "Cost = [[0.0616061]]\n",
            "Cost = [[0.06158743]]\n",
            "Cost = [[0.06156879]]\n",
            "Cost = [[0.06155018]]\n",
            "Cost = [[0.06153161]]\n",
            "Cost = [[0.06151306]]\n",
            "Cost = [[0.06149455]]\n",
            "Cost = [[0.06147607]]\n",
            "Cost = [[0.06145762]]\n",
            "Cost = [[0.0614392]]\n",
            "Cost = [[0.06142081]]\n",
            "Cost = [[0.06140246]]\n",
            "Cost = [[0.06138413]]\n",
            "Cost = [[0.06136584]]\n",
            "Cost = [[0.06134757]]\n",
            "Cost = [[0.06132934]]\n",
            "Cost = [[0.06131114]]\n",
            "Cost = [[0.06129296]]\n",
            "Cost = [[0.06127482]]\n",
            "Cost = [[0.06125671]]\n",
            "Cost = [[0.06123863]]\n",
            "Cost = [[0.06122058]]\n",
            "Cost = [[0.06120256]]\n",
            "Cost = [[0.06118456]]\n",
            "Cost = [[0.0611666]]\n",
            "Cost = [[0.06114867]]\n",
            "Cost = [[0.06113077]]\n",
            "Cost = [[0.0611129]]\n",
            "Cost = [[0.06109505]]\n",
            "Cost = [[0.06107724]]\n",
            "Cost = [[0.06105945]]\n",
            "Cost = [[0.0610417]]\n",
            "Cost = [[0.06102397]]\n",
            "Cost = [[0.06100628]]\n",
            "Cost = [[0.06098861]]\n",
            "Cost = [[0.06097097]]\n",
            "Cost = [[0.06095336]]\n",
            "Cost = [[0.06093578]]\n",
            "Cost = [[0.06091822]]\n",
            "Cost = [[0.0609007]]\n",
            "Cost = [[0.0608832]]\n",
            "Cost = [[0.06086574]]\n",
            "Cost = [[0.0608483]]\n",
            "Cost = [[0.06083088]]\n",
            "Cost = [[0.0608135]]\n",
            "Cost = [[0.06079615]]\n",
            "Cost = [[0.06077882]]\n",
            "Cost = [[0.06076152]]\n",
            "Cost = [[0.06074425]]\n",
            "Cost = [[0.06072701]]\n",
            "Cost = [[0.06070979]]\n",
            "Cost = [[0.0606926]]\n",
            "Cost = [[0.06067544]]\n",
            "Cost = [[0.06065831]]\n",
            "Cost = [[0.0606412]]\n",
            "Cost = [[0.06062412]]\n",
            "Cost = [[0.06060707]]\n",
            "Cost = [[0.06059005]]\n",
            "Cost = [[0.06057305]]\n",
            "Cost = [[0.06055608]]\n",
            "Cost = [[0.06053914]]\n",
            "Cost = [[0.06052222]]\n",
            "Cost = [[0.06050533]]\n",
            "Cost = [[0.06048847]]\n",
            "Cost = [[0.06047163]]\n",
            "Cost = [[0.06045482]]\n",
            "Cost = [[0.06043804]]\n",
            "Cost = [[0.06042128]]\n",
            "Cost = [[0.06040455]]\n",
            "Cost = [[0.06038785]]\n",
            "Cost = [[0.06037117]]\n",
            "Cost = [[0.06035452]]\n",
            "Cost = [[0.06033789]]\n",
            "Cost = [[0.06032129]]\n",
            "Cost = [[0.06030472]]\n",
            "Cost = [[0.06028817]]\n",
            "Cost = [[0.06027164]]\n",
            "Cost = [[0.06025515]]\n",
            "Cost = [[0.06023867]]\n",
            "Cost = [[0.06022223]]\n",
            "Cost = [[0.06020581]]\n",
            "Cost = [[0.06018941]]\n",
            "Cost = [[0.06017304]]\n",
            "Cost = [[0.0601567]]\n",
            "Cost = [[0.06014038]]\n",
            "Cost = [[0.06012408]]\n",
            "Cost = [[0.06010781]]\n",
            "Cost = [[0.06009157]]\n",
            "Cost = [[0.06007535]]\n",
            "Cost = [[0.06005916]]\n",
            "Cost = [[0.06004298]]\n",
            "Cost = [[0.06002684]]\n",
            "Cost = [[0.06001072]]\n",
            "Cost = [[0.05999462]]\n",
            "Cost = [[0.05997855]]\n",
            "Cost = [[0.0599625]]\n",
            "Cost = [[0.05994648]]\n",
            "Cost = [[0.05993048]]\n",
            "Cost = [[0.05991451]]\n",
            "Cost = [[0.05989856]]\n",
            "Cost = [[0.05988263]]\n",
            "Cost = [[0.05986673]]\n",
            "Cost = [[0.05985085]]\n",
            "Cost = [[0.059835]]\n",
            "Cost = [[0.05981917]]\n",
            "Cost = [[0.05980336]]\n",
            "Cost = [[0.05978758]]\n",
            "Cost = [[0.05977182]]\n",
            "Cost = [[0.05975608]]\n",
            "Cost = [[0.05974037]]\n",
            "Cost = [[0.05972468]]\n",
            "Cost = [[0.05970902]]\n",
            "Cost = [[0.05969338]]\n",
            "Cost = [[0.05967776]]\n",
            "Cost = [[0.05966216]]\n",
            "Cost = [[0.05964659]]\n",
            "Cost = [[0.05963104]]\n",
            "Cost = [[0.05961552]]\n",
            "Cost = [[0.05960001]]\n",
            "Cost = [[0.05958453]]\n",
            "Cost = [[0.05956908]]\n",
            "Cost = [[0.05955364]]\n",
            "Cost = [[0.05953823]]\n",
            "Cost = [[0.05952284]]\n",
            "Cost = [[0.05950748]]\n",
            "Cost = [[0.05949213]]\n",
            "Cost = [[0.05947681]]\n",
            "Cost = [[0.05946151]]\n",
            "Cost = [[0.05944624]]\n",
            "Cost = [[0.05943098]]\n",
            "Cost = [[0.05941575]]\n",
            "Cost = [[0.05940054]]\n",
            "Cost = [[0.05938535]]\n",
            "Cost = [[0.05937019]]\n",
            "Cost = [[0.05935505]]\n",
            "Cost = [[0.05933992]]\n",
            "Cost = [[0.05932483]]\n",
            "Cost = [[0.05930975]]\n",
            "Cost = [[0.05929469]]\n",
            "Cost = [[0.05927966]]\n",
            "Cost = [[0.05926465]]\n",
            "Cost = [[0.05924966]]\n",
            "Cost = [[0.05923469]]\n",
            "Cost = [[0.05921974]]\n",
            "Cost = [[0.05920482]]\n",
            "Cost = [[0.05918991]]\n",
            "Cost = [[0.05917503]]\n",
            "Cost = [[0.05916017]]\n",
            "Cost = [[0.05914533]]\n",
            "Cost = [[0.05913051]]\n",
            "Cost = [[0.05911571]]\n",
            "Cost = [[0.05910093]]\n",
            "Cost = [[0.05908618]]\n",
            "Cost = [[0.05907144]]\n",
            "Cost = [[0.05905673]]\n",
            "Cost = [[0.05904204]]\n",
            "Cost = [[0.05902736]]\n",
            "Cost = [[0.05901271]]\n",
            "Cost = [[0.05899808]]\n",
            "Cost = [[0.05898347]]\n",
            "Cost = [[0.05896888]]\n",
            "Cost = [[0.05895432]]\n",
            "Cost = [[0.05893977]]\n",
            "Cost = [[0.05892524]]\n",
            "Cost = [[0.05891073]]\n",
            "Cost = [[0.05889625]]\n",
            "Cost = [[0.05888178]]\n",
            "Cost = [[0.05886733]]\n",
            "Cost = [[0.05885291]]\n",
            "Cost = [[0.0588385]]\n",
            "Cost = [[0.05882412]]\n",
            "Cost = [[0.05880975]]\n",
            "Cost = [[0.05879541]]\n",
            "Cost = [[0.05878108]]\n",
            "Cost = [[0.05876678]]\n",
            "Cost = [[0.05875249]]\n",
            "Cost = [[0.05873823]]\n",
            "Cost = [[0.05872398]]\n",
            "Cost = [[0.05870975]]\n",
            "Cost = [[0.05869555]]\n",
            "Cost = [[0.05868136]]\n",
            "Cost = [[0.05866719]]\n",
            "Cost = [[0.05865305]]\n",
            "Cost = [[0.05863892]]\n",
            "Cost = [[0.05862481]]\n",
            "Cost = [[0.05861072]]\n",
            "Cost = [[0.05859665]]\n",
            "Cost = [[0.0585826]]\n",
            "Cost = [[0.05856857]]\n",
            "Cost = [[0.05855456]]\n",
            "Cost = [[0.05854056]]\n",
            "Cost = [[0.05852659]]\n",
            "Cost = [[0.05851264]]\n",
            "Cost = [[0.0584987]]\n",
            "Cost = [[0.05848478]]\n",
            "Cost = [[0.05847089]]\n",
            "Cost = [[0.05845701]]\n",
            "Cost = [[0.05844315]]\n",
            "Cost = [[0.05842931]]\n",
            "Cost = [[0.05841548]]\n",
            "Cost = [[0.05840168]]\n",
            "Cost = [[0.0583879]]\n",
            "Cost = [[0.05837413]]\n",
            "Cost = [[0.05836038]]\n",
            "Cost = [[0.05834665]]\n",
            "Cost = [[0.05833294]]\n",
            "Cost = [[0.05831925]]\n",
            "Cost = [[0.05830558]]\n",
            "Cost = [[0.05829192]]\n",
            "Cost = [[0.05827828]]\n",
            "Cost = [[0.05826467]]\n",
            "Cost = [[0.05825106]]\n",
            "Cost = [[0.05823748]]\n",
            "Cost = [[0.05822392]]\n",
            "Cost = [[0.05821037]]\n",
            "Cost = [[0.05819684]]\n",
            "Cost = [[0.05818333]]\n",
            "Cost = [[0.05816984]]\n",
            "Cost = [[0.05815637]]\n",
            "Cost = [[0.05814291]]\n",
            "Cost = [[0.05812947]]\n",
            "Cost = [[0.05811605]]\n",
            "Cost = [[0.05810265]]\n",
            "Cost = [[0.05808927]]\n",
            "Cost = [[0.0580759]]\n",
            "Cost = [[0.05806255]]\n",
            "Cost = [[0.05804922]]\n",
            "Cost = [[0.0580359]]\n",
            "Cost = [[0.05802261]]\n",
            "Cost = [[0.05800933]]\n",
            "Cost = [[0.05799606]]\n",
            "Cost = [[0.05798282]]\n",
            "Cost = [[0.05796959]]\n",
            "Cost = [[0.05795638]]\n",
            "Cost = [[0.05794319]]\n",
            "Cost = [[0.05793001]]\n",
            "Cost = [[0.05791686]]\n",
            "Cost = [[0.05790372]]\n",
            "Cost = [[0.05789059]]\n",
            "Cost = [[0.05787749]]\n",
            "Cost = [[0.0578644]]\n",
            "Cost = [[0.05785132]]\n",
            "Cost = [[0.05783827]]\n",
            "Cost = [[0.05782523]]\n",
            "Cost = [[0.05781221]]\n",
            "Cost = [[0.0577992]]\n",
            "Cost = [[0.05778621]]\n",
            "Cost = [[0.05777324]]\n",
            "Cost = [[0.05776029]]\n",
            "Cost = [[0.05774735]]\n",
            "Cost = [[0.05773443]]\n",
            "Cost = [[0.05772152]]\n",
            "Cost = [[0.05770863]]\n",
            "Cost = [[0.05769576]]\n",
            "Cost = [[0.05768291]]\n",
            "Cost = [[0.05767007]]\n",
            "Cost = [[0.05765725]]\n",
            "Cost = [[0.05764444]]\n",
            "Cost = [[0.05763165]]\n",
            "Cost = [[0.05761888]]\n",
            "Cost = [[0.05760612]]\n",
            "Cost = [[0.05759338]]\n",
            "Cost = [[0.05758066]]\n",
            "Cost = [[0.05756795]]\n",
            "Cost = [[0.05755526]]\n",
            "Cost = [[0.05754258]]\n",
            "Cost = [[0.05752992]]\n",
            "Cost = [[0.05751728]]\n",
            "Cost = [[0.05750465]]\n",
            "Cost = [[0.05749204]]\n",
            "Cost = [[0.05747944]]\n",
            "Cost = [[0.05746686]]\n",
            "Cost = [[0.0574543]]\n",
            "Cost = [[0.05744175]]\n",
            "Cost = [[0.05742922]]\n",
            "Cost = [[0.0574167]]\n",
            "Cost = [[0.0574042]]\n",
            "Cost = [[0.05739171]]\n",
            "Cost = [[0.05737924]]\n",
            "Cost = [[0.05736679]]\n",
            "Cost = [[0.05735435]]\n",
            "Cost = [[0.05734193]]\n",
            "Training completed!\n",
            "Final parameters shape: (514, 1)\n",
            "\n",
            "4. Plotting training progress...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "5. Making predictions on the test set...\n",
            "First 5 predictions on test set (probabilities):\n",
            "[0.8527517  0.99997204 0.00174529 0.00215748 0.99955472]\n",
            "First 5 predicted classes on test set:\n",
            "[1 1 0 0 1]\n",
            "\n",
            "6. Evaluating model performance on the test set...\n",
            "--- Test Set Evaluation ---\n",
            "Accuracy: 0.9682\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.96      0.98      0.97      1156\n",
            "         1.0       0.98      0.96      0.97      1171\n",
            "\n",
            "    accuracy                           0.97      2327\n",
            "   macro avg       0.97      0.97      0.97      2327\n",
            "weighted avg       0.97      0.97      0.97      2327\n",
            "\n",
            "\n",
            "--- Training Set Evaluation ---\n",
            "Accuracy: 0.9805\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      0.98      0.98      4754\n",
            "         1.0       0.98      0.98      0.98      4551\n",
            "\n",
            "    accuracy                           0.98      9305\n",
            "   macro avg       0.98      0.98      0.98      9305\n",
            "weighted avg       0.98      0.98      0.98      9305\n",
            "\n",
            "\n",
            "=== Training and Evaluation Summary ===\n",
            "Dataset: 11632 samples, 513 features\n",
            "Training samples: 9305\n",
            "Testing samples: 2327\n",
            "Final training accuracy: 0.9805\n",
            "Final test accuracy: 0.9682\n",
            "Final training cost: 0.057342\n",
            "Model trained and evaluated successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QERav-U4Pf85"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}